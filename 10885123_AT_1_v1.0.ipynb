{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image # To grab the images and extract useful information\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "np.random.seed(42) # Set random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4870, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes: Added train_selected directory in my working directory.\n",
    "#        Extracted all files from train_selected.zip\n",
    "# Set the dataset directory\n",
    "dataset_dir = os.getcwd() + \"/train_selected\"\n",
    "\n",
    "# Get the data labels\n",
    "labels_file = dataset_dir + \"/train_selected.csv\"\n",
    "data_labels = pd.read_csv(labels_file)\n",
    "\n",
    "data_labels.shape\n",
    "# dataset_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get X files\n",
    "file_list = [dataset_dir + \"/\" + str(x) + \".png\" for x in list(data_labels[\"id\"])]\n",
    "# file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4370\n",
       "1     500\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the labels\n",
    "# finds column label with value = 'automobile' and assigns value 1 if true or 0 if false\n",
    "data_labels[\"class\"] = np.where(data_labels['label']=='automobile', 1, 0) \n",
    "# counts the number of unique values, sum of 1s and 0s\n",
    "data_labels[\"class\"].value_counts()\n",
    "# data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Create a function that will standardise the dataset\n",
    "# Replace False\n",
    "\n",
    "def standarise_data(dataset):\n",
    "    # to standardise pixel data divide by 255\n",
    "    new_dataset = dataset/255.\n",
    "     \n",
    "    return new_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    global X_train, X_test, y_train, y_test, X, y\n",
    "\n",
    "    # loads the image files into an array, considers the number of pixels and colors.\n",
    "    X = np.array([np.array(Image.open(fname)) for fname in file_list])\n",
    "    \n",
    "    # loads the class into an array\n",
    "    y = np.array(data_labels[\"class\"])\n",
    "    \n",
    "    # sets the split of training ang testing datasets, random_state ensure that every run will provide the same results\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # y_train.shape[0] gets the number of rows\n",
    "    y_train = y_train.reshape(1, y_train.shape[0])\n",
    "    y_test = y_test.reshape(1, y_test.shape[0])\n",
    "    \n",
    "    # Reshape the training and test examples \n",
    "    X_train_f = X_train.reshape(X_train.shape[0], -1).T\n",
    "    X_test_f = X_test.reshape(X_test.shape[0], -1).T\n",
    "    \n",
    "       \n",
    "    # Standardize data to have feature values between 0 and 1.\n",
    "    X_train = standarise_data(X_train_f)\n",
    "    X_test = standarise_data(X_test_f)\n",
    "    \n",
    "    X_train = np.squeeze(X_train)\n",
    "    X_test = np.squeeze(X_test)\n",
    "    \n",
    "    print (\"Flatten X_train: \" + str(X_train.shape))\n",
    "    print (\"Flatten X_test: \" + str(X_test.shape))\n",
    "    \n",
    "    print (\"y_train: \" + str(y_train.shape))\n",
    "    print (\"y_test: \" + str(y_test.shape))\n",
    "    \n",
    "    # print (\"Flatten X_train_f: \" + str(X_train_f.shape))\n",
    "    # print (\"Flatten X_test_f: \" + str(X_test_f.shape))\n",
    "    \n",
    "       \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten X_train: (3072, 3409)\n",
      "Flatten X_test: (3072, 1461)\n",
      "y_train: (1, 3409)\n",
      "y_test: (1, 1461)\n"
     ]
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick 'normal' ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the following resources useful:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3409, 3072) (1461, 3072) (3409,) (1461,)\n"
     ]
    }
   ],
   "source": [
    "X_train_clf = X_train.T\n",
    "X_test_clf = X_test.T\n",
    "\n",
    "y_train_clf = y_train.T.ravel()\n",
    "y_test_clf = y_test.T.ravel()\n",
    "\n",
    "print(X_train_clf.shape, X_test_clf.shape, y_train_clf.shape, y_test_clf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   3 out of  10 | elapsed:  4.8min remaining: 11.3min\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Total time taken: 0:07:22.430503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV \n",
    "import datetime\n",
    "\n",
    "C_list = np.linspace(0.001, 0.5, 20)\n",
    "log_reg = LogisticRegressionCV(\n",
    "    Cs=C_list, cv=10, penalty='l2', scoring='roc_auc', solver='liblinear', tol =1e-4, max_iter=1000, \n",
    "    class_weight='balanced', n_jobs=7, verbose=2, refit=True, multi_class='ovr', random_state=42\n",
    ")\n",
    "\n",
    "#Fit to our model\n",
    "start = datetime.datetime.now()\n",
    "log_reg.fit(X_train_clf, y_train_clf)\n",
    "end = datetime.datetime.now()\n",
    "print(\"Total time taken: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the class\n",
    "y_test_clf = pd.DataFrame(y_test_clf, columns=[\"actual\"])\n",
    "y_test_clf[\"predictions_lr\"] = log_reg.predict(X_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix \n",
      " [[1154  143]\n",
      " [  53  111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      1297\n",
      "           1       0.44      0.68      0.53       164\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1461\n",
      "   macro avg       0.70      0.78      0.73      1461\n",
      "weighted avg       0.90      0.87      0.88      1461\n",
      "\n",
      "ROC-AUC Score \n",
      " 0.7832874174925251\n",
      "Accuracy Score \n",
      " 0.865845311430527\n"
     ]
    }
   ],
   "source": [
    "# Get confusion matrix \n",
    "print(\"Confustion Matrix \\n\", confusion_matrix(y_test_clf.actual, y_test_clf.predictions_lr))\n",
    "\n",
    "# Get classification report\n",
    "print(classification_report(y_test_clf.actual, y_test_clf.predictions_lr))\n",
    "\n",
    "# Get ROC-AUC\n",
    "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test_clf.actual, y_test_clf.predictions_lr))\n",
    "\n",
    "# Get accuracy\n",
    "print(\"Accuracy Score \\n\", accuracy_score(y_test_clf.actual, y_test_clf.predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:   42.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 0:00:54.318810\n"
     ]
    }
   ],
   "source": [
    "# A tree based example\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import datetime\n",
    "\n",
    "#Create the model object\n",
    "rf_class = RandomForestClassifier(\n",
    "    n_estimators=1000, criterion='entropy', \n",
    "    max_depth=15, min_samples_split=3, bootstrap=True, oob_score=True, \n",
    "    n_jobs=7, random_state=42, verbose=1, class_weight='balanced' \n",
    ")\n",
    "\n",
    "#Fit to our model\n",
    "start = datetime.datetime.now()\n",
    "rf_class.fit(X_train_clf, y_train_clf)\n",
    "end = datetime.datetime.now()\n",
    "print(\"Total time taken: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "#Predict the class\n",
    "y_test_clf[\"predictions_rf\"] = rf_class.predict(X_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix \n",
      " [[1297    0]\n",
      " [ 151   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      1297\n",
      "           1       1.00      0.08      0.15       164\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1461\n",
      "   macro avg       0.95      0.54      0.55      1461\n",
      "weighted avg       0.91      0.90      0.86      1461\n",
      "\n",
      "ROC-AUC Score \n",
      " 0.5396341463414634\n",
      "Accuracy Score \n",
      " 0.8966461327857632\n"
     ]
    }
   ],
   "source": [
    "# Get confusion matrix \n",
    "print(\"Confustion Matrix \\n\", confusion_matrix(y_test_clf.actual, y_test_clf.predictions_rf))\n",
    "\n",
    "# Get classification report\n",
    "print(classification_report(y_test_clf.actual, y_test_clf.predictions_rf))\n",
    "\n",
    "# Get ROC-AUC\n",
    "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test_clf.actual, y_test_clf.predictions_rf))\n",
    "\n",
    "# Get accuracy\n",
    "print(\"Accuracy Score \\n\", accuracy_score(y_test_clf.actual, y_test_clf.predictions_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Correctly create the layer dimensions as per the brief\n",
    "# Replace False\n",
    "\n",
    "# For example layer_dimensions of [5,7,2,1] would be input 5, two hidden layers (7,2) and 1 in output\n",
    "\n",
    "layer_dimensions = ([X_train.shape[0],10,25,10,1])\n",
    "#len(layer_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Use your knowledge of parameter matrix size to edit the code. \n",
    "# Replace False\n",
    "\n",
    "def initialise_parameters(layer_dimensions):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    layer_dimensions -- python (list), one item per layer, number representing size of layer\n",
    "    \n",
    "    Output:\n",
    "    parameters -- python dictionary containing your weight and bias parameters \"W1\", \"b1\", ..., \"WL\", \"bL\" \n",
    "                  with appropriate sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    global parameters\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    parameters = {}\n",
    "    L = len(layer_dimensions)  \n",
    "    \n",
    "    for l in range(1, L):\n",
    "#       parameters['W' + str(l)] = np.random.randn(layer_dimensions[l], layer_dimensions[l-1]) * 0.01 \n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dimensions[l], layer_dimensions[l-1]) * np.sqrt(2./layer_dimensions[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dimensions[l], 1)) \n",
    "        # print(l)\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward prop\n",
    "Create a series of functions that will:\n",
    "\n",
    "Undertake the linear multiplication\n",
    "Underake the activation of the layer\n",
    "Store this somewhere for efficient computation of backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations\n",
    "We will need activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Create a function that will undertake sigmoid activaiton\n",
    "# Create another function that will undertake relu activation\n",
    "# Replace False\n",
    "\n",
    "def sigmoid(Z):\n",
    "    \"\"\"    \n",
    "    Input:\n",
    "    Z     -- numpy array of any shape\n",
    "    \n",
    "    Output:\n",
    "    A     -- output of sigmoid(z), (should be same shape as Z!)\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "        \n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"    \n",
    "    Input:\n",
    "    Z     -- numpy array of any shape\n",
    "    \n",
    "    Output:\n",
    "    A     -- output of relu(z), (should be same shape as Z!)\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0, Z)\n",
    "    \n",
    "    cache = Z \n",
    "    \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Create a function that will undertake the linear component of forward prop\n",
    "# Replace False\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A     -- activations from previous layer\n",
    "    W     -- weights matrix\n",
    "    b     -- bias vector\n",
    "\n",
    "    Output:\n",
    "    Z     -- the input to activation function \n",
    "    cache -- a python dictionary with \"A\", \"W\" and \"b\" for backprop\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W,A) + b\n",
    "    \n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# This function conditionally calls an activation function. \n",
    "# Call the correction function above with the correct if statement\n",
    "# Replace False\n",
    "\n",
    "def activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "    A_prev     -- activations from previous layer\n",
    "    W          -- weights matrix\n",
    "    b          -- bias vector\n",
    "    activation -- the activation type to be used (\"sigmoid\" or \"relu\")\n",
    "\n",
    "    Output:\n",
    "    A          -- the output of the activation function, also called the post-activation value \n",
    "    cache      -- a python dictionary with two two caches \"linear_cache\" and \"activation_cache\" for backprop\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    ###NOTE###\n",
    "    # This is where you can put more activation functions for the extension tasks\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Architect the forward pass. \n",
    "# You will need to firstly determine how many layers there are\n",
    "# You will then need to pull out the correct parameters we initalised\n",
    "# Ensure you use the appropriate activation for the middle layers\n",
    "# Pay special attention to the last layer\n",
    "# It may help to print out parameters\n",
    "# Replace False\n",
    "\n",
    "def total_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "    X            -- raw data\n",
    "    parameters   -- dictionary of initialised parameters, output from a particular function above.\n",
    "    \n",
    "    Returns:\n",
    "    AL           -- last post-activation value\n",
    "    caches       -- list of caches from forward activations\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(layer_dimensions) - 1\n",
    "        \n",
    "    \n",
    "    # All the layers up until the last (sigmoid) layer\n",
    "    for l in range(1, L):\n",
    "  \n",
    "        A_prev = A \n",
    "        A, cache = activation_forward(A_prev, \n",
    "                                      parameters['W' + str(l)], \n",
    "                                      parameters['b' + str(l)], \n",
    "                                      activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "                                                 \n",
    "    # The last layer - how do we use the sigmoid function?\n",
    "    \n",
    "    AL, cache = activation_forward(A, \n",
    "                                      parameters['W' + str(L)], \n",
    "                                      parameters['b' + str(L)], \n",
    "                                      activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Differentiate the relu and the sigmoid functions\n",
    "# Replace False\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    dA      -- post-activation gradient\n",
    "    cache   -- 'Z' that is used in the backwards prop here.\n",
    "\n",
    "    Output:\n",
    "    dZ      -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.copy(dA) # Copying dA first\n",
    "    \n",
    "    # What do you set dZ to when Z is what values? \n",
    "    # dZ = np.multiply(dA, np.int64(Z > 0))\n",
    "    dZ = np.where(Z < 0, 0, dZ)\n",
    "        \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    dA      -- post-activation gradient\n",
    "    cache   -- 'Z' that is used in backprop here\n",
    "\n",
    "    Returns:\n",
    "    dZ      -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You do not need to do anything here, but notes are included for your interest\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    dZ        -- Gradient of the cost with respect to 'Z' of current layer\n",
    "    cache     -- (A_prev, W, b) from forward propag in the current layer, we stored this previously\n",
    "\n",
    "    Output:\n",
    "    dA_prev   -- Gradient of the cost w.r.t activation of previous layer\n",
    "    dW        -- Gradient of the cost w.r.t W of current layer\n",
    "    db        -- Gradient of the cost w.r.t b of current layer l\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Use the activation differentiation functions you created above\n",
    "# Ensure you are putting the right arguments (hint: caches) into the functions\n",
    "# For the first false, consider what function give back dZ? (what does it require?)\n",
    "# Replace False\n",
    "\n",
    "def activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    dA         -- post-activation gradient for current layer\n",
    "    cache      -- (linear_cache, activation_cache) stored previously for backprop\n",
    "    activation -- activation for this layer (\"sigmoid\" or \"relu\")\n",
    "    \n",
    "    Output:\n",
    "    dA_prev   -- Gradient of the cost w.r.t activation of previous layer\n",
    "    dW        -- Gradient of the cost w.r.t W of current layer\n",
    "    db        -- Gradient of the cost w.r.t b of current layer l\n",
    "    \"\"\"\n",
    "    \n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache) \n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache) \n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Differentiate the loss function with respect to the last activation layer\n",
    "# Replace False\n",
    "\n",
    "def total_backward(AL, Y, caches):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    AL        -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y         -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches    -- list of caches from relu and sigmoid we kept from forward prop\n",
    "    \n",
    "    output:\n",
    "    grads     -- A dictionary with the gradients named dA+l,dW+l, db+l for each layer\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y,AL) - np.divide(1 - Y, 1 - AL))\n",
    "    # dAL = np.divide(AL - y, np.multiply(AL, 1 - AL))\n",
    "    # dAL = AL * (1-AL)\n",
    "\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Write a function to compute the binary logistic cost function ('cross entropy loss')\n",
    "# This is on page 51 of the slides from block_1. \n",
    "# You may need to transpose elements to make the matrix calculations work\n",
    "# Replace False\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    AL    -- probability vector for label predictions\n",
    "    Y     -- truth vector vector\n",
    "\n",
    "    Output:\n",
    "    cost  -- cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # Compute loss from aL and y.\n",
    "    cost_total =  - (np.dot(Y,np.log(AL).T) + np.dot(1- Y,np.log(1-AL).T))\n",
    "    cost = (1./m) * cost_total \n",
    "    \n",
    "    cost = np.squeeze(cost) # Help with the shape\n",
    "    # assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Update each parameter\n",
    "# Remember what hyperparameter is important for this step?\n",
    "# You will also find a useful, indexed value in the 'grads' dictionary created in backprop above\n",
    "# Replace False\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "    parameters    -- dictionary with parameters \n",
    "    grads         -- dictionary with gradients (which function outputs this?)\n",
    "    learning_date -- step size to adjust parameters by\n",
    "    \n",
    "    Returns:\n",
    "    parameters    -- dictionary containing your updated parameters , same structure as original parameters dict\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 ### number of layers\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to knit together everything you have done so far and allow for different layer sizes and lengths to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Now stitch it all together. Essentially you will need to call all your functions in turn with the right arguments.\n",
    "# Initialise parameters\n",
    "# Undertake forward prop. What is our master function? Consider what we got from initialisation?\n",
    "# Undertake backwards prop. Again consider our master function for back prop.\n",
    "# Update parameters.\n",
    "# Replace False\n",
    "\n",
    "def total_backward_forward(X, Y, layers_dimensions, \n",
    "                           learning_rate, \n",
    "                           num_iterations, \n",
    "                           print_cost):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X                 -- data\n",
    "    Y                 -- truth vector (1,0)'s\n",
    "    layers_dimensions -- list of dimensions for each layer of network\n",
    "    learning_rate     -- step size for gradient descent\n",
    "    num_iterations    -- number of training iterations to undertake\n",
    "    print_cost        -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    output:\n",
    "    parameters        -- parameters learnt by the model. Used to predict\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    costs = []\n",
    "    \n",
    "    # Parameters initialization\n",
    "    parameters = initialise_parameters(layer_dimensions)\n",
    "     \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation:\n",
    "        AL, caches = total_forward(X, parameters)\n",
    "         \n",
    "        # Compute cost\n",
    "        cost = compute_cost(AL, Y)\n",
    "            \n",
    "        # Backward propagation.\n",
    "        grads = total_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.405542\n",
      "Cost after iteration 100: 0.294678\n",
      "Cost after iteration 200: 0.254238\n",
      "Cost after iteration 300: 0.228810\n",
      "Cost after iteration 400: 0.214546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = total_backward_forward(X_train, \n",
    "                                    y_train, \n",
    "                                    layer_dimensions, \n",
    "                                    learning_rate = 0.01,\n",
    "                                    num_iterations = 500, \n",
    "                                    print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict (Hold out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO ##\n",
    "\n",
    "# Create your own predict function.\n",
    "# Note the number of training examples\n",
    "# Turn the probabilities into 0-1 predictions\n",
    "# Replace False\n",
    "\n",
    "def predict(X, y, parameters):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "    X           -- data (test set)\n",
    "    parameters  -- parameters of the trained model\n",
    "    \n",
    "    Output:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0] # How many training examples?\n",
    "    print('m: ' + str(m))\n",
    "    n = len(parameters) // 2\n",
    "    print('n: ' + str(n))\n",
    "    p = np.zeros((1,m)) # Initialise probabilities to zero\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = total_forward(X, parameters)\n",
    "    print('probas: ' + str(probas))\n",
    "    \n",
    "    # convert probas to 0/1 predictions. \n",
    "    p = np.where(probas >= 0.5,1,0)\n",
    "            \n",
    "    return p, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 3072\n",
      "n: 4\n",
      "probas: [[0.2151078  0.02820747 0.01864151 ... 0.00406337 0.03386647 0.07343476]]\n"
     ]
    }
   ],
   "source": [
    "# Create some predictions\n",
    "predictions, probas = predict(X_test, y_test, parameters)\n",
    "# print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f81b9142e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a scatter plot of probabilities. Good check if something is wrong\n",
    "plt.scatter(range(len(probas[0])), probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1388\n",
       "1      73\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check your prediction value counts\n",
    "pred_df = pd.DataFrame(predictions[0], columns=[\"prediction\"])\n",
    "pred_df.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 1)\n",
      "(1461, 1)\n"
     ]
    }
   ],
   "source": [
    "# Do a bit of reshaping\n",
    "predictions_sk = predictions.reshape(len(predictions[0]), 1)\n",
    "print(predictions_sk.shape)\n",
    "\n",
    "y_test_sk = y_test.T\n",
    "print(y_test_sk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix \n",
      " [[1275   22]\n",
      " [ 113   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1297\n",
      "           1       0.70      0.31      0.43       164\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1461\n",
      "   macro avg       0.81      0.65      0.69      1461\n",
      "weighted avg       0.89      0.91      0.89      1461\n",
      "\n",
      "Accuracy:  0.9075975359342916\n",
      "ROC_AUC:  0.8538277826880043\n"
     ]
    }
   ],
   "source": [
    "# Build some sklearn scores\n",
    "\n",
    "#Get confusion matrix \n",
    "print(\"Confustion Matrix \\n\", confusion_matrix(list(y_test_sk), list(predictions_sk)))\n",
    "\n",
    "#Get classification report\n",
    "print(classification_report(y_test_sk, predictions_sk))\n",
    "\n",
    "# Accuracy score\n",
    "print(\"Accuracy: \", accuracy_score(y_test_sk, predictions_sk))\n",
    "\n",
    "# ROC_AUC score\n",
    "print(\"ROC_AUC: \", roc_auc_score(y_test_sk, probas.T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
